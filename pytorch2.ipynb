{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     12\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1=cv2.imread(\"reference.jpg\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(img1))\n",
    "VAL_RATIO = 0.2\n",
    "#The ratio of the total training set used only for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "1905 7620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8392, 0.8431, 0.8706,  ..., 0.0157, 0.0314, 0.0157],\n",
       "          [0.8431, 0.8431, 0.8627,  ..., 0.5804, 0.3529, 0.2235],\n",
       "          [0.8471, 0.8431, 0.8510,  ..., 0.3490, 0.2627, 0.1725],\n",
       "          ...,\n",
       "          [0.6627, 0.6784, 0.6902,  ..., 0.9294, 0.9490, 0.9529],\n",
       "          [0.6667, 0.6706, 0.6745,  ..., 0.8941, 0.9176, 0.9137],\n",
       "          [0.6549, 0.6627, 0.6627,  ..., 0.8902, 0.8941, 0.8902]],\n",
       " \n",
       "         [[0.6941, 0.6941, 0.7098,  ..., 0.0000, 0.0157, 0.0000],\n",
       "          [0.6980, 0.6941, 0.7020,  ..., 0.5686, 0.3373, 0.2039],\n",
       "          [0.7020, 0.6941, 0.7020,  ..., 0.3255, 0.2471, 0.1569],\n",
       "          ...,\n",
       "          [0.5255, 0.5294, 0.5412,  ..., 0.9137, 0.9333, 0.9451],\n",
       "          [0.5333, 0.5373, 0.5412,  ..., 0.8824, 0.9059, 0.9059],\n",
       "          [0.5373, 0.5451, 0.5451,  ..., 0.8784, 0.8824, 0.8863]],\n",
       " \n",
       "         [[0.6196, 0.6196, 0.6392,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6235, 0.6196, 0.6314,  ..., 0.5098, 0.3020, 0.1804],\n",
       "          [0.6275, 0.6196, 0.6275,  ..., 0.2706, 0.2039, 0.1216],\n",
       "          ...,\n",
       "          [0.3765, 0.3843, 0.3961,  ..., 0.8667, 0.8863, 0.8941],\n",
       "          [0.3843, 0.3882, 0.3922,  ..., 0.8235, 0.8471, 0.8471],\n",
       "          [0.3882, 0.3961, 0.3961,  ..., 0.8118, 0.8157, 0.8157]]]),\n",
       " 1933)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = torchvision.datasets.LFWPeople(\"data\",split=\"train\", download=True, transform=transforms.ToTensor())\n",
    "\n",
    "INPUT_SHAPE = (3,250,250)\n",
    "VAL_RATIO = 0.2\n",
    "val_len = int(len(dataset) * VAL_RATIO)\n",
    "train_len = len(dataset) - val_len\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, val_len])\n",
    "\n",
    "print(val_len,train_len)\n",
    "\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7620, 7620, 1905, 1905)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape\n",
    "len(train_dataset), len(train_dataset), len(val_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([3, 250, 250])\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "transform = transforms.ToPILImage()\n",
    "img = transform(image)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 127"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
